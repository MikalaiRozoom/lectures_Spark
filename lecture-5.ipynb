{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#RDD\" data-toc-modified-id=\"RDD-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>RDD</a></span><ul class=\"toc-item\"><li><span><a href=\"#map(-)\" data-toc-modified-id=\"map(-)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>map( )</a></span></li><li><span><a href=\"#filter(-)\" data-toc-modified-id=\"filter(-)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>filter( )</a></span></li><li><span><a href=\"#distinct(-)\" data-toc-modified-id=\"distinct(-)-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>distinct( )</a></span></li><li><span><a href=\"#union()\" data-toc-modified-id=\"union()-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>union()</a></span></li><li><span><a href=\"#reduce\" data-toc-modified-id=\"reduce-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>reduce</a></span></li><li><span><a href=\"#intersection(-)\" data-toc-modified-id=\"intersection(-)-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>intersection( )</a></span></li><li><span><a href=\"#subtract(-)\" data-toc-modified-id=\"subtract(-)-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>subtract( )</a></span></li><li><span><a href=\"#sample()\" data-toc-modified-id=\"sample()-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>sample()</a></span></li></ul></li><li><span><a href=\"#PAIR-RDD-Transformations\" data-toc-modified-id=\"PAIR-RDD-Transformations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>PAIR RDD Transformations</a></span><ul class=\"toc-item\"><li><span><a href=\"#groupByKey()\" data-toc-modified-id=\"groupByKey()-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>groupByKey()</a></span></li><li><span><a href=\"#reduceByKey()\" data-toc-modified-id=\"reduceByKey()-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>reduceByKey()</a></span></li><li><span><a href=\"#sortByKey()\" data-toc-modified-id=\"sortByKey()-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>sortByKey()</a></span></li><li><span><a href=\"#subtractByKey()\" data-toc-modified-id=\"subtractByKey()-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>subtractByKey()</a></span></li><li><span><a href=\"#countByKey()\" data-toc-modified-id=\"countByKey()-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>countByKey()</a></span></li><li><span><a href=\"#join()\" data-toc-modified-id=\"join()-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>join()</a></span></li></ul></li><li><span><a href=\"#RDD-Actions\" data-toc-modified-id=\"RDD-Actions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>RDD Actions</a></span><ul class=\"toc-item\"><li><span><a href=\"#collect()\" data-toc-modified-id=\"collect()-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>collect()</a></span></li></ul></li><li><span><a href=\"#Broadcast-read-only-Variables\" data-toc-modified-id=\"Broadcast-read-only-Variables-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Broadcast read-only Variables</a></span></li><li><span><a href=\"#PySpark-Accumulator\" data-toc-modified-id=\"PySpark-Accumulator-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>PySpark Accumulator</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "mydata = [1, 2, 2, 3, 4, 5, 5, 5, 6]\n",
    "rdd = sc.parallelize(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "new_RDD = rdd.map(lambda x: x * 2)\n",
    "\n",
    "new_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "new_RDD = rdd.filter(lambda x: x >= 4)\n",
    "\n",
    "new_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distinct( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "new_RDD = rdd.distinct()\n",
    "\n",
    "new_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### union()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd2 = sc.parallelize([2, 2, 3, 5, 6, 6, 7, 8, 9])\n",
    "new_RDD = rdd.union(rdd2)\n",
    "new_RDD.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intersection( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "new_RDD = rdd.intersection(rdd2)\n",
    "\n",
    "new_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subtract( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "new_RDD = rdd.subtract(rdd2)\n",
    "\n",
    "new_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "new_RDD = rdd.sample(False, 0.5)\n",
    "\n",
    "new_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIR RDD Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd=sc.parallelize([ \n",
    "    (1, 2),\n",
    "    (1, 5),\n",
    "    (3, 4),\n",
    "    (3, 6)])\n",
    "\n",
    "rdd.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduceByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.groupByKey().map(lambda x:(x[0], list(x[1])) ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.groupByKey().map(lambda x:(x[0], sum(x[1])) ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.sortByKey(ascending=False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subtractByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd2=sc.parallelize([(1,9)])\n",
    "\n",
    "rdd.subtractByKey(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.countByKey().items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd.join(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "rdd = sc.parallelize([2, 2, 3, 5, 6, 6, 7, 8, 9, 0])\n",
    "\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "new_rdd=sc.parallelize([1, 2, 3, 4])\n",
    "\n",
    "new_rdd.aggregate((0, 0), \n",
    "    (lambda x, y:(x[0] + y, x[1] + 1)), \n",
    "    (lambda x, y:(x[0] + y[0], x[1] + y[1])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "# In Python\n",
    "# Create an RDD of tuples (name, age)\n",
    "\n",
    "dataRDD = sc.parallelize(\n",
    "    [(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)]\n",
    "    )\n",
    "\n",
    "# Use map and reduceByKey transformations with their lambda\n",
    "# expressions to aggregate and then compute average\n",
    "\n",
    "agesRDD = (dataRDD\n",
    ".map(lambda x: (x[0], (x[1], 1)))\n",
    ".reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    ".map(lambda x: (x[0], x[1][0] / x[1][1])))\n",
    "\n",
    "agesRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "dataRDD\\\n",
    ".map(lambda x: (x[0], (x[1], 1))) \\\n",
    ".reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "data_df = spark.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    "(\"TD\", 35), (\"Brooke\", 25)], [\"name\", \"age\"])\n",
    "\n",
    "# Group the same names together, aggregate their ages, and compute an average\n",
    "avg_df = data_df.groupBy(\"name\").agg(avg(\"age\"))\n",
    "\n",
    "avg_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast read-only Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
    "broadcastStates = spark.sparkContext.broadcast(states)\n",
    "\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "def state_convert(code):\n",
    "    return broadcastStates.value[code]\n",
    "\n",
    "result = df.rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).toDF(columns)\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "accum=spark.sparkContext.accumulator(0)\n",
    "rdd=spark.sparkContext.parallelize([1,2,3,4,5])\n",
    "rdd.foreach(lambda x:accum.add(x))\n",
    "print(accum.value)\n",
    "\n",
    "accuSum=spark.sparkContext.accumulator(0)\n",
    "def countFun(x):\n",
    "    global accuSum\n",
    "    accuSum+=x\n",
    "rdd.foreach(countFun)\n",
    "print(accuSum.value)\n",
    "\n",
    "accumCount=spark.sparkContext.accumulator(0)\n",
    "rdd2=spark.sparkContext.parallelize([1,2,3,4,5])\n",
    "rdd2.foreach(lambda x:accumCount.add(1))\n",
    "print(accumCount.value)"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1820,
    "start_time": "2021-12-02T23:15:57.972Z"
   },
   {
    "duration": 113,
    "start_time": "2021-12-02T23:15:59.794Z"
   },
   {
    "duration": 16,
    "start_time": "2021-12-02T23:16:01.802Z"
   },
   {
    "duration": 9,
    "start_time": "2021-12-02T23:16:04.022Z"
   },
   {
    "duration": 8,
    "start_time": "2021-12-02T23:16:06.131Z"
   },
   {
    "duration": 15,
    "start_time": "2021-12-02T23:16:07.242Z"
   },
   {
    "duration": 398,
    "start_time": "2021-12-02T23:16:08.129Z"
   },
   {
    "duration": 10,
    "start_time": "2021-12-02T23:16:17.583Z"
   },
   {
    "duration": 3,
    "start_time": "2021-12-02T23:16:18.198Z"
   },
   {
    "duration": 9,
    "start_time": "2021-12-02T23:16:18.793Z"
   },
   {
    "duration": 11,
    "start_time": "2021-12-02T23:16:21.930Z"
   },
   {
    "duration": 7,
    "start_time": "2021-12-02T23:16:22.378Z"
   },
   {
    "duration": 260,
    "start_time": "2021-12-02T23:16:30.000Z"
   },
   {
    "duration": 5,
    "start_time": "2021-12-02T23:16:34.629Z"
   },
   {
    "duration": 2934,
    "start_time": "2021-12-02T23:16:35.275Z"
   },
   {
    "duration": 7,
    "start_time": "2021-12-02T23:16:41.192Z"
   },
   {
    "duration": 397,
    "start_time": "2021-12-02T23:16:41.783Z"
   },
   {
    "duration": 245,
    "start_time": "2021-12-02T23:16:45.015Z"
   },
   {
    "duration": 4,
    "start_time": "2021-12-02T23:17:25.956Z"
   },
   {
    "duration": 11,
    "start_time": "2021-12-02T23:17:26.132Z"
   },
   {
    "duration": 7,
    "start_time": "2021-12-02T23:17:32.388Z"
   },
   {
    "duration": 698,
    "start_time": "2021-12-02T23:17:34.958Z"
   },
   {
    "duration": 1414,
    "start_time": "2021-12-02T23:17:38.152Z"
   },
   {
    "duration": 7,
    "start_time": "2021-12-02T23:17:41.927Z"
   },
   {
    "duration": 1572,
    "start_time": "2021-12-02T23:17:43.848Z"
   },
   {
    "duration": 1156,
    "start_time": "2021-12-02T23:17:48.999Z"
   },
   {
    "duration": 23205,
    "start_time": "2021-12-07T18:42:27.953Z"
   },
   {
    "duration": 2694,
    "start_time": "2021-12-07T18:45:34.103Z"
   },
   {
    "duration": 302,
    "start_time": "2021-12-07T19:15:48.509Z"
   },
   {
    "duration": 21043,
    "start_time": "2021-12-07T19:15:48.813Z"
   },
   {
    "duration": 3,
    "start_time": "2021-12-07T19:49:43.957Z"
   },
   {
    "duration": 2,
    "start_time": "2021-12-07T19:57:11.654Z"
   },
   {
    "duration": 2,
    "start_time": "2021-12-07T20:07:12.050Z"
   },
   {
    "duration": 2,
    "start_time": "2021-12-07T20:14:58.374Z"
   },
   {
    "duration": 86,
    "start_time": "2021-12-10T10:58:16.325Z"
   },
   {
    "duration": 4,
    "start_time": "2021-12-10T11:14:07.509Z"
   },
   {
    "duration": 3,
    "start_time": "2021-12-10T11:50:50.819Z"
   },
   {
    "duration": 2,
    "start_time": "2021-12-10T11:51:29.786Z"
   },
   {
    "duration": 4,
    "start_time": "2021-12-10T11:55:04.872Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "801px",
    "left": "24px",
    "top": "110px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
